{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5268e8a7-23c3-49f3-8a17-a109414657d8",
   "metadata": {},
   "source": [
    "# ğŸ§­ Guided Exercise: Newtonâ€“Raphson Step for a Quadratic Function\n",
    "\n",
    "Letâ€™s consider the function:\n",
    "\n",
    "$$\n",
    "f(x) = (x - 2)^2 - 2 = x^2 - 4x + 2\n",
    "$$\n",
    "\n",
    "This function has a stationary point at $ x_s = 2 $.  In the language of geometry optimization, this would be an equilibrium geometry.\n",
    "\n",
    "Weâ€™ll start at an initial guess $ x_0 = 0 $ and see how the **Newtonâ€“Raphson method** finds the optimal step toward the stationary point.\n",
    "\n",
    "---\n",
    "\n",
    "## âœï¸ Step 1: Define the function and its derivatives\n",
    "\n",
    "Using the expressions given:\n",
    "\n",
    "$$\n",
    "f(x) = x^2 - 4x + 2, \\quad\n",
    "f'(x) = 2x - 4, \\quad\n",
    "f''(x) = 2\n",
    "$$\n",
    "\n",
    "ğŸ‘‰ **Your task:** Complete the functions below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0909110-5fcc-4bcf-8fe1-5741aa6991ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define f(x), f'(x), and f''(x)\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"Return f(x) = x^2 - 4x + 2\"\"\"\n",
    "    f_x = ### complete with appropriate code\n",
    "    return f_x\n",
    "\n",
    "def fprime(x):\n",
    "    \"\"\"Return the first derivative f'(x) = 2x - 4\"\"\"\n",
    "    fp_x = ### complete with appropriate code\n",
    "    return fp_x \n",
    "\n",
    "def fdoubleprime(x):\n",
    "    \"\"\"Return the second derivative f''(x) = 2\"\"\"\n",
    "    fpp_x = ### complete with appropriate code\n",
    "    return fpp_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347db503-89d3-4cce-9df6-96ec3b677dfa",
   "metadata": {},
   "source": [
    "## ğŸ” Step 2: Evaluate at the initial point\n",
    "\n",
    "Weâ€™ll start from $ x_0 = 0 $.\n",
    "\n",
    "ğŸ‘‰ **Your task:** Evaluate $ f(x_0) $, $ f'(x_0) $, and $ f''(x_0) $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df24352-9547-483c-9364-c5a7bd396d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 1.0\n",
    "\n",
    "# TODO: Compute f(x0), f'(x0), f''(x0)\n",
    "f_x0 = # complete with appropriate function call\n",
    "fp_x0 = # complete with appropriate function call\n",
    "fpp_x0 =  # complete with appropriate function call\n",
    "\n",
    "print(f\"f({x0}) = {f_x0}\")\n",
    "print(f\"f'({x0}) = {fp_x0}\")\n",
    "print(f\"f''({x0}) = {fpp_x0}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de456f3-1106-4580-8a65-7683181c840b",
   "metadata": {},
   "source": [
    "## ğŸ§® Step 3: Find the optimal step\n",
    "\n",
    "From the Taylor expansion, we know the Newtonâ€“Raphson step is:\n",
    "\n",
    "$$\n",
    "\\Delta x = -\\frac{f'(x_0)}{f''(x_0)}\n",
    "$$\n",
    "\n",
    "ğŸ‘‰ **Your task:** Compute $\\Delta x $ and the updated point $ x_1 = x_0 + \\Delta x $.\n",
    "Do this by hand first and then complete the following code to do the computation with python.  Compare your answers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cceab1-9975-4c1d-8516-70098859364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute the Newtonâ€“Raphson step\n",
    "dx = -fp_x0 / fpp_x0\n",
    "x1 = x0 + dx\n",
    "\n",
    "print(f\"Newton-Raphson step Î”x = {dx}\")\n",
    "print(f\"Updated point x1 = {x1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1489c2e4-59fc-48f8-bedc-31ef330eabc2",
   "metadata": {},
   "source": [
    "âœ… **Question:** Does $ x_1 $ match the true stationary point $ x_s = 2 $?  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ Discussion\n",
    "\n",
    "Because our function is perfectly quadratic, the Newtonâ€“Raphson step finds the stationary point **in a single iteration**.  \n",
    "\n",
    "In later examples, weâ€™ll see what happens when $ f(x) $ isnâ€™t purely quadratic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30201dc1-a980-4407-8a96-b2b8499fae61",
   "metadata": {},
   "source": [
    "# ğŸ¨ Step 4: Visualizing the Newtonâ€“Raphson Step\n",
    "\n",
    "Now that weâ€™ve computed the step $ \\Delta x $, letâ€™s visualize whatâ€™s happening.\n",
    "\n",
    "Weâ€™ll plot the function $ f(x) = x^2 - 4x + 2 $, mark the initial point $ x_0 $, and show the tangent line scaled by the inverse of the second derivative at that point.\n",
    "\n",
    "The Newtonâ€“Raphson step moves from $ x_0 $ to the point where this scaled tangent crosses the $ x $-axix. For this quadratic case, this lands exactly on the stationary point $ x_s = 2 $.\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ‘‰ Run the cell below to see this plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e33a06e-a73b-4ccf-8c78-a7727fc970b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define range of x values for plotting\n",
    "x = np.linspace(-1, 4, 200)\n",
    "\n",
    "# Compute function and tangent line values\n",
    "y = f(x)\n",
    "\n",
    "# Tangent line at x0:\n",
    "# f(x_tangent) = f(x0) + f'(x0)*(x_tangent - x0)\n",
    "y_tangent = f_x0 + fp_x0 / fpp_x0 * (x - x0)\n",
    "\n",
    "# TODO: Create the plot showing f(x), tangent line, and key points\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Plot the function\n",
    "plt.plot(x, y, label=r\"$f(x) = x^2 - 4x + 2$\")\n",
    "\n",
    "# Plot the tangent line\n",
    "plt.plot(x, y_tangent, '--', label=\"Tangent scaled by 1 / f''(x_0) at $x_0$\")\n",
    "\n",
    "# Mark the initial point\n",
    "plt.scatter(x0, f_x0, color='red', zorder=3, label=r\"$x_0$\")\n",
    "\n",
    "# Mark the stationary point\n",
    "plt.scatter(x1, f(x1), color='green', zorder=3, label=r\"$x_1$ (stationary point)\")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.title(\"Newtonâ€“Raphson Step for a Quadratic Function\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45ffd0d-7fa2-4b6a-a346-a1303dc16e93",
   "metadata": {},
   "source": [
    "# ğŸš€ Guided Exercise: Newtonâ€“Raphson Method for a Non-Quadratic Function\n",
    "\n",
    "In the previous example, we saw that Newtonâ€“Raphson reached the stationary point of a *quadratic* function in **one step** â€” because the functionâ€™s curvature was constant.\n",
    "\n",
    "Now, letâ€™s consider a function that **is not exactly quadratic**:\n",
    "\n",
    "$$\n",
    "f(x) = x^3 + x^2 - 5\n",
    "$$\n",
    "\n",
    "The stationary points are at $ x_s = 0 $ and $ x_s = -\\tfrac{2}{3} $,  \n",
    "but imagine we donâ€™t know these ahead of time.  \n",
    "\n",
    "Weâ€™ll start from an initial guess $ x_0 = 1 $ and try to find the stationary point iteratively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82f3f4-f29c-4a8c-8242-4f468682f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define the new function and its derivatives\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"Return f(x) = x^3 + x^2 - 5\"\"\"\n",
    "    return x**3 + x**2 - 5\n",
    "\n",
    "def fprime(x):\n",
    "    \"\"\"Return f'(x) = 3x^2 + 2x\"\"\"\n",
    "    return 3*x**2 + 2*x\n",
    "\n",
    "def fdoubleprime(x):\n",
    "    \"\"\"Return f''(x) = 6x + 2\"\"\"\n",
    "    return 6*x + 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f324e2-1692-4605-87bc-93e5efb35602",
   "metadata": {},
   "source": [
    "## ğŸ” Step 1: Compute the Newtonâ€“Raphson update\n",
    "\n",
    "The update rule for finding stationary points is:\n",
    "\n",
    "$$\n",
    "x_{n+1} = x_n - \\frac{f'(x_n)}{f''(x_n)}\n",
    "$$\n",
    "\n",
    "ğŸ‘‰ **Your task:** Implement one iteration of the Newtonâ€“Raphson step starting from $ x_0 = 1 $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac1f97-828c-4b4e-9e34-435a9f5d1a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 1.0\n",
    "\n",
    "# Compute one iteration\n",
    "x1 = # complete code with appropriate update\n",
    "\n",
    "print(f\"x0 = {x0:.4f}\")\n",
    "print(f\"x1 = {x1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e57db5-23ca-4eb1-a69f-59f0cde71543",
   "metadata": {},
   "source": [
    "âœ… **Question:**  \n",
    "How close is your updated value $ x_1$ to one of the true stationary points ($ x_s = 0 $ or $ x_s = -2/3 $)?\n",
    "\n",
    "You should notice that one iteration isnâ€™t enough this time because the function is *not quadratic*, so the curvature changes with $ x $.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd64c475-10d4-4c35-9382-01d506cf86be",
   "metadata": {},
   "source": [
    "## ğŸ”„ Step 2: Iterate until convergence\n",
    "\n",
    "ğŸ‘‰ **Your task:** Write a small loop to perform several Newtonâ€“Raphson iterations.\n",
    "\n",
    "Stop when the change between iterations $|x_{n+1} - x_n|$ becomes very small (e.g. less than $10^{-6}$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbec49ac-cbed-4942-b238-fd5b8cc32d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement an iterative Newtonâ€“Raphson loop\n",
    "\n",
    "x = 1.0\n",
    "tol = 1e-6\n",
    "max_iter = 20\n",
    "\n",
    "for i in range(max_iter):\n",
    "    x_new = # complete with appropriate update to the variable x_new\n",
    "    print(f\"Iteration {i:2d}: x = {x:.6f}\")\n",
    "    if abs(x_new - x) < tol:\n",
    "        print(f\"Converged to stationary point at x = {x_new:.6f}\")\n",
    "        break\n",
    "    x = x_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c8d520-0cbc-43fc-b24d-9aebf70b9343",
   "metadata": {},
   "source": [
    "# ğŸ§­ Guided Exercise: Newtonâ€“Raphson Method in Two Dimensions\n",
    "\n",
    "In one dimension, we wrote the Newtonâ€“Raphson update for finding a stationary point as\n",
    "\n",
    "$$\n",
    "x_{n+1} = x_n - \\frac{f'(x_n)}{f''(x_n)}.\n",
    "$$\n",
    "\n",
    "In **two dimensions (and higher)**, this generalizes to:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{n+1} = \\mathbf{x}_n - \\mathbf{H}^{-1}(\\mathbf{x}_n) \\, \\nabla f(\\mathbf{x}_n)\n",
    "$$\n",
    "\n",
    "where  \n",
    "- $ \\nabla f(\\mathbf{x}) $ is the **gradient vector**, and  \n",
    "- $ \\mathbf{H}(\\mathbf{x}) $ is the **Hessian matrix** (matrix of second derivatives).\n",
    "\n",
    "Weâ€™ll begin with a **perfectly quadratic function** where Newtonâ€™s method finds the minimum in a single step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92cd9aa-bb3f-4f81-81e4-8400684745a6",
   "metadata": {},
   "source": [
    "## âœï¸ Step 1: Perfectly Quadratic 2D Function\n",
    "\n",
    "Letâ€™s consider\n",
    "\n",
    "$\n",
    "f(x, y) = (x - 1)^2 + 2(y - 2)^2.\n",
    "$\n",
    "\n",
    "This function has its stationary point (and minimum) at $ (x_s, y_s) = (1, 2) $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4110328-9387-4c91-9072-f299f04defd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the function, gradient, and Hessian\n",
    "def f(x, y):\n",
    "    fxy = ### Complete with 2D function computing (x-1)^2 + 2(y-2)^2\n",
    "    return fxy\n",
    "\n",
    "def grad_f(x, y):\n",
    "    \"\"\"Gradient vector âˆ‡f = [âˆ‚f/âˆ‚x, âˆ‚f/âˆ‚y]\"\"\"\n",
    "    dfdx = ### complete with partial first derivative of f(x,y) wrt x\n",
    "    dfdy = ### complete with partial first derivative of f(x,y) wrt y\n",
    "    return np.array([dfdx, dfdy])\n",
    "\n",
    "def hessian_f(x, y):\n",
    "    \"\"\"Hessian matrix H = [[âˆ‚Â²f/âˆ‚xÂ², âˆ‚Â²f/âˆ‚xâˆ‚y], [âˆ‚Â²f/âˆ‚yâˆ‚x, âˆ‚Â²f/âˆ‚yÂ²]]\"\"\"\n",
    "    d2fx2 = ### complete with âˆ‚Â²f/âˆ‚xÂ²\n",
    "    d2fxy = ### complete with âˆ‚Â²f/âˆ‚xâˆ‚y\n",
    "    d2fyx = ### complete with âˆ‚Â²f/âˆ‚yâˆ‚x\n",
    "    d2fy2 = ### complete with âˆ‚Â²f/âˆ‚yÂ²\n",
    "    \n",
    "    return np.array([[d2fx2, d2fxy],\n",
    "                     [d2fyx, d2fy2]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11509332-75a7-4656-a867-cfd93f04904d",
   "metadata": {},
   "source": [
    "## ğŸ” Step 2: Perform one Newtonâ€“Raphson step\n",
    "\n",
    "Start from an initial point $\\mathbf{x}_0 = (0, 0) $ and compute one Newton update:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_1 = \\mathbf{x}_0 - \\mathbf{H}^{-1}(\\mathbf{x}_0) \\nabla f(\\mathbf{x}_0)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e88b4d9-b1ec-428b-bd60-f24afba7f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy0 = np.array([0.0, 0.0])\n",
    "\n",
    "# Compute gradient and Hessian\n",
    "g = ## call function to compute grad of f(x,y) at point given by xy0 \n",
    "H = ## call function to compute Hessian of f(x,y) at point given by xy0\n",
    "\n",
    "# Newton update\n",
    "x1 = xy0 - np.linalg.inv(H) @ g\n",
    "\n",
    "print(\"x0 =\", xy0)\n",
    "print(\"Gradient =\", g)\n",
    "print(\"x1 =\", x1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdbf4c8-1364-4e42-a974-91460157e87a",
   "metadata": {},
   "source": [
    "âœ… **Question:**  \n",
    "Does your single update step land exactly on the stationary point $ (1, 2) $?  \n",
    "Why does it only take one step for this function?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e954b1-6c1f-4050-8359-34db80879d26",
   "metadata": {},
   "source": [
    "# ğŸŒŠ Step 3: Newtonâ€“Raphson on a Non-Quadratic 2D Function\n",
    "\n",
    "Now letâ€™s consider a *non-quadratic* function, where the curvature changes with position:\n",
    "\n",
    "$$\n",
    "f(x, y) = \\sin(x) + \\cos(y)\n",
    "$$\n",
    "\n",
    "This function has stationary points where both partial derivatives vanish:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x} = \\cos(x) = 0, \\quad \\frac{\\partial f}{\\partial y} = -\\sin(y) = 0.\n",
    "$$\n",
    "\n",
    "That means stationary points occur when $ x = \\pi/2 + n\\pi $ and $ y = n\\pi $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317979c7-8188-47ef-9077-a7c2dfb5c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function, gradient, and Hessian for the sinusoidal surface\n",
    "def f2(x, y):\n",
    "    fxy = ### complete with f(x,y) = sin(x) + cos(y)\n",
    "    return fxy\n",
    "\n",
    "def grad_f2(x, y):\n",
    "    dfdx = ### complete with dfdx\n",
    "    dfdy = ### complete with dfdy\n",
    "    return np.array([dfdx, dfdy])\n",
    "\n",
    "def hessian_f2(x, y):\n",
    "    d2fx2 = ### complete with âˆ‚Â²f/âˆ‚xÂ²\n",
    "    d2fxy = ### complete with âˆ‚Â²f/âˆ‚xâˆ‚y\n",
    "    d2fyx = ### complete with âˆ‚Â²f/âˆ‚yâˆ‚x\n",
    "    d2fy2 = ### complete with âˆ‚Â²f/âˆ‚yÂ²\n",
    "    \n",
    "    return np.array([[d2fx2, d2fxy],\n",
    "                     [d2fyx, d2fy2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528ec2a5-15a0-47d0-840e-e32112530df3",
   "metadata": {},
   "source": [
    "## ğŸ”„ Step 4: Iterate Newtonâ€“Raphson updates\n",
    "\n",
    "The next block will put these updated functions for $f(x,y) = {\\rm sin}(x) + {\\rm cos}(y)$ starting from $ (x_0, y_0) = (2, 1) $ and apply a few Newton steps to find a nearby stationary point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8943feb7-3b18-4601-bc9c-edcb530333f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([2.0, 1.0])\n",
    "tol = 1e-6\n",
    "max_iter = 10\n",
    "\n",
    "for i in range(max_iter):\n",
    "    g = grad_f2(*x)\n",
    "    H = hessian_f2(*x)\n",
    "    step = np.linalg.solve(H, g)  # equivalent to inv(H) @ g but more stable\n",
    "    x_new = x - step\n",
    "    print(f\"Iter {i:2d}: x = {x}, f(x) = {f2(*x):.4f}\")\n",
    "    if np.linalg.norm(x_new - x) < tol:\n",
    "        print(f\"Converged to stationary point: {x_new}\")\n",
    "        break\n",
    "    x = x_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7615e4-5434-44e6-8663-c099fc09dca8",
   "metadata": {},
   "source": [
    "âœ… **Questions:**\n",
    "1. Which stationary point does the iteration converge to?  \n",
    "2. What happens if you start from a different initial guess â€” e.g. $ (x_0, y_0) = (0, 0) $?  \n",
    "3. Does the algorithm always converge to a minimum, or can it find a maximum or saddle point?\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ’¡ **Discussion**\n",
    "\n",
    "In 2D, the Newtonâ€“Raphson method uses the **Hessian matrix** to locally approximate the curvature in all directions.  \n",
    "If the Hessian is positive definite, youâ€™re near a **minimum**;  \n",
    "if itâ€™s negative definite, youâ€™re near a **maximum**;  \n",
    "and if it has both positive and negative eigenvalues, youâ€™ve found a **saddle point**.\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ¯ **Challenge Extension**\n",
    "\n",
    "Implement a general function `newton_2d(f, grad_f, hessian_f, x0, tol, max_iter)`  \n",
    "that performs these updates automatically and returns:\n",
    "- the final point,\n",
    "- the number of iterations, and\n",
    "- the trajectory of points for visualization.\n",
    "\n",
    "(You can, in principle, then plot the path of iterations on a contour plot of $ f(x, y) $!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5059157c-1961-4b35-8237-94b4402b7947",
   "metadata": {},
   "source": [
    "# âš™ï¸ Step 5: Finite-Difference Gradients and Hessians\n",
    "\n",
    "So far, weâ€™ve relied on **analytical derivatives** â€” but in many real problems,  \n",
    "we canâ€™t easily compute $ \\nabla f$ or $ \\mathbf{H} $ analytically.\n",
    "\n",
    "A common alternative is to use **finite differences**:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x_i} \\approx \\frac{f(x_i + h) - f(x_i - h)}{2h}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\frac{\\partial^2 f}{\\partial x_i \\partial x_j} \\approx\n",
    "\\frac{f(x_i + h, x_j + h) - f(x_i + h, x_j - h)\n",
    "- f(x_i - h, x_j + h) + f(x_i - h, x_j - h)}{4h^2}.\n",
    "$$\n",
    "\n",
    "where $h$ is some small step along the direction $x_i$ or $x_j$, as appropriate.  This finite difference approximation typically becomes closer to the exact derivative as $h$ approaches zero, so numerically we typically set $h$ to some very small value like $h = 0.001$ Angstroms for molecular geometries. \n",
    "\n",
    "Weâ€™ll test this idea using the same function:\n",
    "\n",
    "$$\n",
    "f(x, y) = \\sin(x) + \\cos(y)\n",
    "$$\n",
    "\n",
    "and compare our **numerical** gradients and Hessians to the **analytical** ones.  Again, it will be adequate to set $h$ to some very small value like $h = 0.001$ for this comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e3b92-837f-422f-9b37-2ed31ce6fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def numerical_grad(f, x, h=1e-3):\n",
    "    \"\"\"\n",
    "    Compute the numerical gradient (âˆ‡f) of a 2D function using central finite differences.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : function\n",
    "        A Python function that takes two arguments, e.g. f(x, y) = sin(x) + cos(y).\n",
    "    x : array-like of shape (2,)\n",
    "        The point [x, y] at which to evaluate the gradient.\n",
    "    h : float, optional\n",
    "        The finite difference step size (default is 1e-3).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    grad : ndarray of shape (2,)\n",
    "        The numerical gradient vector [âˆ‚f/âˆ‚x, âˆ‚f/âˆ‚y].\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize gradient vector with zeros (same dimension as x)\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    # Loop over each coordinate direction (x and y)\n",
    "    for i in range(len(x)):\n",
    "        # Create a step vector for perturbing one coordinate at a time\n",
    "        step = np.zeros_like(x)\n",
    "        step[i] = h\n",
    "\n",
    "        # TODO: Use the central finite-difference formula\n",
    "        # grad[i] = (f(x + step) - f(x - step)) / (2*h)\n",
    "        pass\n",
    "\n",
    "    return grad\n",
    "\n",
    "\n",
    "def numerical_hessian(f, x, h=1e-4):\n",
    "    \"\"\"\n",
    "    Compute the numerical Hessian (matrix of second derivatives) of a 2D function \n",
    "    using central finite differences.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : function\n",
    "        A Python function that takes two arguments, e.g. f(x, y) = sin(x) + cos(y).\n",
    "    x : array-like of shape (2,)\n",
    "        The point [x, y] at which to evaluate the Hessian.\n",
    "    h : float, optional\n",
    "        The finite difference step size (default is 1e-4).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    H : ndarray of shape (2, 2)\n",
    "        The numerical Hessian matrix:\n",
    "            [[âˆ‚Â²f/âˆ‚xÂ², âˆ‚Â²f/âˆ‚xâˆ‚y],\n",
    "             [âˆ‚Â²f/âˆ‚yâˆ‚x, âˆ‚Â²f/âˆ‚yÂ²]]\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize empty Hessian matrix\n",
    "    n = len(x)\n",
    "    H = np.zeros((n, n))\n",
    "\n",
    "    # Double loop over indices (i, j)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            # Create small step vectors along the i-th and j-th directions\n",
    "            ei = np.zeros_like(x)\n",
    "            ej = np.zeros_like(x)\n",
    "            ei[i] = h\n",
    "            ej[j] = h\n",
    "\n",
    "            # TODO: Use the 4-point central difference formula for second derivatives:\n",
    "            # fpp = f(x + ei + ej)\n",
    "            # fpm = f(x + ei - ej)\n",
    "            # fmp = f(x - ei + ej)\n",
    "            # fmm = f(x - ei - ej)\n",
    "            #\n",
    "            # H[i, j] = (fpp - fpm - fmp + fmm) / (4 * h * h)\n",
    "            pass\n",
    "\n",
    "    return H\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32dabd7-5222-4967-a200-050f727c97ab",
   "metadata": {},
   "source": [
    "âœ… **Your task:**\n",
    "- Complete the formulas in each loop according to the provided comments.  \n",
    "- Test your functions using `f2(x, y) = np.sin(x) + np.cos(y)` at a few points (e.g. `[2, 1]`).\n",
    "- Compare your numerical derivatives with the analytical ones to check accuracy.\n",
    "\n",
    "ğŸ’­ **Hint:**  \n",
    "Remember that the function `f` takes *two separate arguments* (x and y),  \n",
    "so when calling it inside your loop youâ€™ll want to unpack the array `x` using `*x`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a295881a-01ea-4865-8580-fd9b60d1cb83",
   "metadata": {},
   "source": [
    "# âš›ï¸ Step 7: Numerical Gradients from Quantum Chemistry Calculations\n",
    "\n",
    "So far, weâ€™ve used simple mathematical functions like $ f(x, y) = \\sin(x) + \\cos(y) $\n",
    "to test our numerical gradient and Hessian code.\n",
    "\n",
    "Letâ€™s now connect this idea to a *real chemistry application*:\n",
    "computing the **potential energy surface** of a molecule using *ab initio* methods.\n",
    "\n",
    "In this example, weâ€™ll use the **PySCF** package to compute the total electronic energy of CO \n",
    "as a function of the Câ€“O bond length.\n",
    "\n",
    "Weâ€™ll then see how we could use the same finite-difference formulas to estimate\n",
    "the **numerical gradient** (and eventually, the curvature) of that potential energy surface.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6559da44-27e7-4e4e-8858-79d0b54dbc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyscf\n",
      "  Downloading pyscf-2.11.0-py3-none-macosx_10_9_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy!=1.16,!=1.17,>=1.13 in /opt/anaconda3/envs/jbook/lib/python3.11/site-packages (from pyscf) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/envs/jbook/lib/python3.11/site-packages (from pyscf) (1.16.0)\n",
      "Collecting h5py>=2.7 (from pyscf)\n",
      "  Downloading h5py-3.15.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/jbook/lib/python3.11/site-packages (from pyscf) (78.1.1)\n",
      "Downloading pyscf-2.11.0-py3-none-macosx_10_9_x86_64.whl (35.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m660.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.15.1-cp311-cp311-macosx_10_9_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m576.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: h5py, pyscf\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/2\u001b[0m [pyscf]32m1/2\u001b[0m [pyscf]\n",
      "\u001b[1A\u001b[2KSuccessfully installed h5py-3.15.1 pyscf-2.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyscf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ac9d6-1516-459b-b04d-c3835a54d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyscf import gto, scf\n",
    "\n",
    "# Conversion factor: Angstrom â†’ Bohr (atomic units)\n",
    "ang_to_au = 1.88973\n",
    "\n",
    "# Template for the CO molecule\n",
    "mol_template = \"\"\"\n",
    "C 0 0 0\n",
    "O {} 0 0\n",
    "\"\"\"\n",
    "\n",
    "def compute_energy(R_CO_angstrom):\n",
    "    \"\"\"\n",
    "    Compute the RHF total energy (in Hartrees) for CO at a given Câ€“O distance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    R_CO_angstrom : float\n",
    "        The Câ€“O bond length in Angstroms.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    energy : float\n",
    "        The Hartreeâ€“Fock total energy (in Hartree atomic units).\n",
    "    \"\"\"\n",
    "    mol = gto.M(\n",
    "        atom=mol_template.format(R_CO_angstrom),\n",
    "        basis='cc-pvdz',\n",
    "        verbose=0,\n",
    "        spin=0\n",
    "    )\n",
    "    mf = scf.RHF(mol)\n",
    "    mf.kernel()\n",
    "    return mf.e_tot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ce6133-3c7e-4f52-bfc3-1bb5725a9b45",
   "metadata": {},
   "source": [
    "# âš™ï¸ Step 1: Potential Energy Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b5f73f-852d-4084-88b8-07baf0f63f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 0.01  # step size in Angstroms\n",
    "x = np.arange(0.8, 1.6, dx)\n",
    "\n",
    "hf_energies = [compute_energy(R) for R in x]\n",
    "\n",
    "print(\"First few RHF energies (Hartree):\")\n",
    "print(hf_energies[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bfd722-a1d5-4b17-a189-cc9df0e7407b",
   "metadata": {},
   "source": [
    "âœ… **Question:**  \n",
    "What trend do you see in the energy values as the bond length changes?  \n",
    "Where roughly is the equilibrium bond length?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b407c40-0bb7-455e-ae7f-ebab41aad150",
   "metadata": {},
   "source": [
    "# ğŸ§® Step 2: Numerical Gradient from Energy Differences\n",
    "\n",
    "Now letâ€™s numerically differentiate this energy function to estimate the force on the atoms â€”\n",
    "just like our earlier finite-difference gradients!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d121ee6c-95d4-4042-a85f-ccd25c13cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient_energy(f, R, h=0.01):\n",
    "    \"\"\"\n",
    "    Compute numerical derivative of energy with respect to bond length (force),\n",
    "    using a central finite difference formula.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : callable\n",
    "        A function that returns the molecular energy at a given bond length.\n",
    "    R : float\n",
    "        Current bond length in Angstroms.\n",
    "    h : float, optional\n",
    "        Step size in Angstroms (default 0.01 Ã…).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dE_dR : float\n",
    "        Numerical derivative of energy with respect to R (Hartree per Angstrom).\n",
    "    \"\"\"\n",
    "    E_plus = f(R + h)\n",
    "    E_minus = f(R - h)\n",
    "    dE_dR = (E_plus - E_minus) / (2 * h)\n",
    "    return dE_dR\n",
    "\n",
    "# Try evaluating at R = 1.2 Ã…\n",
    "R0 = 1.2\n",
    "grad_R = numerical_gradient_energy(compute_energy, R0)\n",
    "print(f\"Numerical dE/dR at R = {R0:.2f} Ã… = {grad_R:.6f} Hartree/Ã…\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fcc35b-be12-464a-9fb4-ac5b87e7fe84",
   "metadata": {},
   "source": [
    "âœ… **Questions:**\n",
    "1. At what bond length does your numerical gradient change sign?  \n",
    "   (Thatâ€™s the equilibrium bond length!)\n",
    "2. How many energy evaluations does it take to compute this gradient?\n",
    "3. What would happen if you needed to compute **gradients for all atomic coordinates** in a polyatomic molecule?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d46737-04b7-464b-ab64-c4961776936c",
   "metadata": {},
   "source": [
    "# ğŸ§® Step 8: 1D Newtonâ€“Raphson Geometry Optimization of CO\n",
    "\n",
    "Now that we can compute the molecular energy \\( E(R) \\) and its numerical derivative \n",
    "\\( \\frac{dE}{dR} \\), we can perform a simple **geometry optimization**.\n",
    "\n",
    "For a diatomic molecule, this means finding the bond length \\( R \\) that minimizes the total energy.\n",
    "\n",
    "Weâ€™ll use the **1D Newtonâ€“Raphson method**, applied to the derivative of the potential energy:\n",
    "\\[\n",
    "R_{n+1} = R_n - \\frac{(dE/dR)}{(d^2E/dR^2)}\n",
    "\\]\n",
    "\n",
    "Since we donâ€™t have an analytic expression for \\( E(R) \\), weâ€™ll also approximate \n",
    "the second derivative (curvature) numerically using finite differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caf254a0-2793-4209-9957-09b4f001378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_second_derivative(f, R, h=0.01):\n",
    "    \"\"\"\n",
    "    Compute the numerical second derivative of energy with respect to bond length\n",
    "    using the central finite-difference formula.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : callable\n",
    "        Function returning molecular energy at a given bond length.\n",
    "    R : float\n",
    "        Current bond length (Angstroms).\n",
    "    h : float, optional\n",
    "        Step size for finite difference (default 0.01 Ã…).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    d2E_dR2 : float\n",
    "        Numerical second derivative (Hartree per Ã…Â²).\n",
    "    \"\"\"\n",
    "    E_plus = f(R + h)\n",
    "    E_minus = f(R - h)\n",
    "    E0 = f(R)\n",
    "    d2E_dR2 = (E_plus - 2 * E0 + E_minus) / (h**2)\n",
    "    return d2E_dR2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "517ce715-5e11-41ab-8ab5-601dbb77766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_optimize_bond(f, R0, tol=1e-5, max_iter=10, h=0.01):\n",
    "    \"\"\"\n",
    "    Perform a 1D Newtonâ€“Raphson optimization of a bond length.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : callable\n",
    "        Function returning molecular energy at a given bond length.\n",
    "    R0 : float\n",
    "        Initial bond length (Angstroms).\n",
    "    tol : float\n",
    "        Convergence tolerance on bond length change (Ã…).\n",
    "    max_iter : int\n",
    "        Maximum number of iterations.\n",
    "    h : float\n",
    "        Step size for numerical derivatives.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    R_opt : float\n",
    "        Optimized bond length (Ã…).\n",
    "    E_opt : float\n",
    "        Energy at optimized geometry (Hartree).\n",
    "    \"\"\"\n",
    "\n",
    "    R = R0\n",
    "    print(f\"Starting optimization from R = {R0:.3f} Ã…\")\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        grad = numerical_gradient_energy(f, R, h)\n",
    "        hess = numerical_second_derivative(f, R, h)\n",
    "\n",
    "        step = -grad / hess\n",
    "        R_new = R + step\n",
    "\n",
    "        print(f\"Iter {i:2d}: R = {R:.4f} Ã…, E = {f(R):.6f} Ha, dE/dR = {grad:.3e}, step = {step:.3e}\")\n",
    "\n",
    "        if abs(step) < tol:\n",
    "            print(f\"\\nâœ… Converged to R = {R_new:.4f} Ã…, E = {f(R_new):.6f} Ha\")\n",
    "            return R_new, f(R_new)\n",
    "\n",
    "        R = R_new\n",
    "\n",
    "    print(\"\\nâš ï¸ Did not converge within max_iter\")\n",
    "    return R, f(R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "216451bf-6ede-487c-9911-8706b72b9b7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_energy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m R_start = \u001b[32m1.4\u001b[39m  \u001b[38;5;66;03m# initial guess in Ã…\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m R_opt, E_opt = newton_optimize_bond(\u001b[43mcompute_energy\u001b[49m, R_start)\n",
      "\u001b[31mNameError\u001b[39m: name 'compute_energy' is not defined"
     ]
    }
   ],
   "source": [
    "R_start = 1.4  # initial guess in Ã…\n",
    "R_opt, E_opt = newton_optimize_bond(compute_energy, R_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ffc0ad1-82db-4b31-8f55-1b677f60bf78",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character 'âœ…' (U+2705) (3312859374.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mâœ… **Questions to Explore**\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid character 'âœ…' (U+2705)\n"
     ]
    }
   ],
   "source": [
    "âœ… **Questions to Explore**\n",
    "1. How many iterations did it take to converge?\n",
    "2. Try changing the initial guess (`R_start = 0.8` or `1.8`).  \n",
    "   Does Newtonâ€“Raphson still converge to the same bond length?\n",
    "3. Why does the second derivative (the curvature) need to be positive at the minimum?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4a88d8-f5e4-483f-802a-9b813891919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸŒ± Preview: Toward Quasi-Newton (BFGS)\n",
    "\n",
    "In the next section, weâ€™ll generalize this:\n",
    "\n",
    "Replace explicit finite-difference Hessians with an updated estimate of curvature.\n",
    "\n",
    "Apply the BFGS update rule, which efficiently refines the Hessian using gradient changes between steps.\n",
    "\n",
    "This will bring us from the conceptually exact but expensive Newtonâ€“Raphson approach\n",
    "to a practically efficient optimization algorithm used in real quantum chemistry geometry optimizers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
